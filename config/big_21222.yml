# Preprocessing: remove stopwords, lower-case all, remove diacritics, remove punctuation
# Vector-Space:  MDS with angular differences between PPMI-Weighted BoWs of all Terms (dimensions 20, 50, 100, 200)
# Candidates:    Frequent Nouns, Adjectives, Nounphrases, Adjectivephrases (doc-freq >= 100 for movies-dataset)
# Cand-Filter:   binary linear SVM with pos/neg-count-ratio as instance cost, then select all for which kappa(svm_rank, count(t,e)) >= 0.1
# Cand-Merging:  Custom

pp_components:                [mfauhcsd2, mfauhtcsldp]
translate_policy:             onlyorig
quantification_measure:       [count, ppmi, tfidf]
dissim_measure:               norm_ang_dist
embed_algo:                   mds
embed_dimensions:             [3, 100, 200]
extraction_method:            all
#TODO: DESC15 hat darauf abgezielt ~22k keywords zu haben => mit meinen params dafÃ¼r sorgen dass ich auch auf sowas komme, mit den aktuellen ists nur 2402!
#candidate_min_term_count:     25 #movies has samples-to-threshold value of 100, placetypes has 35, 20newsgrups has 614, so for 8000 courses any threshold from 2 to 25 seems reasonable (BUT see above, I get too little)!!
#TODO this should be part of the dataset-config!
max_ngram:                    5                   # not explicitly, but it takes adjective phrases so it's something >=3

dcm_quant_measure:            [count, ppmi, tfidf]
classifier:                   SVM
kappa_weights:                [quadratic, linear, None]
classifier_succmetric:        kappa_digitized_onlypos_2
prim_lambda:                  0.4
sec_lambda:                   0.2
__perdataset__:
  placetypes:
    extraction_method: all #in the placetypes-dataset, ALL words are candidates (21.8k)
    pp_components: none

#TODO alles ab cand-filter fehlt noch...

