{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from Levenshtein import distance\n",
    "from os.path import join\n",
    "\n",
    "SEED = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.static.settings import SID_DATA_BASE\n",
    "df = pd.read_csv(join(SID_DATA_BASE, 'kurse-beschreibungen.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='Name')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only consider those with description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Beschreibung'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'desc_len'] = [len(i) for i in df['Beschreibung']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How long are the descriptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minlen, maxlen = max(0,df['desc_len'].mean()-3*df['desc_len'].std()), df['desc_len'].mean()+3*df['desc_len'].std()\n",
    "tmp = df[(df['desc_len'] > minlen) & (df['desc_len'] < maxlen)]\n",
    "tmp['desc_len'].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['desc_len'] < 500].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample-Descriptions: short & long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in df[df['desc_len'] < 100]['Beschreibung'].head(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in df[df['desc_len'] > 3000]['Beschreibung'].head(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select those with at least *some* letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['desc_len'] > 10]\n",
    "df = df.drop(columns='desc_len')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at VeranstaltungsNummer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = df[df.duplicated(subset='VeranstaltungsNummer', keep=False)]\n",
    "zehntel = int(len(dups)/10)\n",
    "start_indices = [10, zehntel, 3*zehntel, 5*zehntel, 7*zehntel]\n",
    "for i in start_indices:\n",
    "    with pd.option_context('display.max_rows', 101, 'display.max_columns', 20, 'display.expand_frame_repr', False, 'display.max_colwidth', 120): \n",
    "        display(dups.sort_values('VeranstaltungsNummer')[i:][['VeranstaltungsNummer', 'Name']].head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**: Kinda non-conclusive. Sometimes the same Veranstaltungsnummer means it's ab duplicate, sometimes it doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace parantheses in titles\n",
    "df['Name'] = df['Name'].str.replace(re.compile(r'\\([^)]*\\)'), '')\n",
    "print(len(df))\n",
    "df = df.drop_duplicates(subset='Name')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 50, 'display.max_columns', 20, 'display.expand_frame_repr', False, 'display.max_colwidth', 5000): \n",
    "    display(df.sample(100, random_state=SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute lower bound "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.drop_duplicates(subset='VeranstaltungsNummer')\n",
    "tmp.loc[:, 'desc_len'] = [len(i) for i in tmp['Beschreibung']]\n",
    "tmp = tmp[tmp['desc_len'] > 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of VLs by first letter of VeranstaltungsNummer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [(i[1]['VeranstaltungsNummer'][0], i[1]['Name'], ind) for ind, i in enumerate(tmp.iterrows())]\n",
    "res_dict = {key: [] for key in [i[0] for i in lst]}\n",
    "for key, val, nr in lst:\n",
    "    res_dict[key].append((val, nr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_it():\n",
    "    num_things = 0\n",
    "    all_dups = {}\n",
    "    for key, val in res_dict.items():\n",
    "        dups = set()\n",
    "        if len(val) > 1:\n",
    "            for numfirst, (first, numfirst) in enumerate(val):\n",
    "                for (second, numsecond) in val[numfirst+1:]:\n",
    "                    if distance(first, second) < 5:\n",
    "                        if num_things < 20:\n",
    "                            print(numsecond, '  ', first, '  |  ',second)\n",
    "                            num_things += 1\n",
    "                        dups.add(numsecond)\n",
    "        all_dups[key] = dups\n",
    "    return all_dups\n",
    "                    \n",
    "dups = do_it()\n",
    "print(dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alls = []\n",
    "for key, val in dups.items():\n",
    "    alls.extend(val)\n",
    "\n",
    "print(len(tmp) - len(alls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Languages\n",
    "\n",
    "TODO: figure out if I make this plot after the correct amount of preprocessing/throwout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = df.set_index(\"Name\")[\"Beschreibung\"].to_dict()\n",
    "\n",
    "languages = defaultdict(lambda : 0)\n",
    "for name, desc in tqdm(di.items()):\n",
    "    try:\n",
    "        languages[detect(desc)] += 1\n",
    "    except LangDetectException as e:\n",
    "        languages[\"unk\"] += 1\n",
    "        \n",
    "languages = dict(languages)\n",
    "languages = dict(sorted(languages.items(), key=lambda x:x[1], reverse=True))\n",
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = [\"de\", \"en\"]\n",
    "disp_lan = {k:v for k,v in languages.items() if k in display}\n",
    "disp_lan[\"other\"] = sum(v for k,v in languages.items() if k not in display)\n",
    "#disp_lan[\"unknown\"] = disp_lan.pop(\"unk\")\n",
    "disp_lan[\"german\"] = disp_lan.pop(\"de\")\n",
    "disp_lan[\"english\"] = disp_lan.pop(\"en\")\n",
    "\n",
    "print(disp_lan)\n",
    "print(sum(disp_lan.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "\n",
    "\n",
    "chart = go.Pie(labels=list(disp_lan.keys()), \n",
    "               values=list(disp_lan.values()), \n",
    "               marker=dict(line=dict(color='#FFF', width=2)),\n",
    "               domain={'x': [0.0, 1], 'y': [0.0, 1]}, \n",
    "               showlegend=False, \n",
    "               name='Language Distribution', \n",
    "               textinfo='label+value+percent')\n",
    "\n",
    "#layout = go.Layout(height = 600, width = 1000, autosize = False,\n",
    "#                   title = 'Language Distribution for the dataset-descriptions')\n",
    "\n",
    "layout = go.Layout(autosize=True)\n",
    "\n",
    "fig = go.Figure(data =[chart], layout = layout)\n",
    "fig.update_traces(textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=16, uniformtext_mode='hide')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fachbereiche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fb_classifier.preprocess_data import make_classifier_class\n",
    "from src.fb_classifier.util.load_data import load_data\n",
    "import os\n",
    "from src.static.settings import SID_DATA_BASE\n",
    "\n",
    "data = load_data({\"all\": os.path.join(SID_DATA_BASE, \"kurse-beschreibungen.csv\")})\n",
    "make_classifier_class(\"all\", data[\"all\"], save_plot=\"./faculty_plot.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "* Estimated absolute lower bound for useful entries: ~5.8k\n",
    "* More likely ~21k useful entries\n",
    "* The Schokeard-Paper uses 14k, 1.3k, 11k, 3.7k Datasets\n",
    "\n",
    "--> Seems possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After-notes\n",
    "\n",
    "**Achtung** bspw die Sprachenzentrum-Kurse haben alle die gleiche Beshcreibung obwohl's komplett verschiedene sind"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
