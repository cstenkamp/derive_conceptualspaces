{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e497cf-40ce-4001-b2bd-48a0244d889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import join, isdir, isfile, abspath, dirname, splitext, basename, split\n",
    "from collections import Counter\n",
    "\n",
    "import pyperclip\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from Levenshtein import distance\n",
    "import pandas as pd\n",
    "\n",
    "from derive_conceptualspace.create_spaces.translate_descriptions import get_langs\n",
    "from derive_conceptualspace.util.mpl_tools import show_hist\n",
    "from derive_conceptualspace.util.result_analysis_tools import df_to_latex, highlight_nonzero_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142c7771-cf2c-41f2-9d85-f42f19f21146",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = lambda iterable: list({i:None for i in iterable}.keys())\n",
    "flatten = lambda l: [item for sublist in l for item in sublist] \n",
    "\n",
    "BOOK_BASE = \"/home/chris/Documents/UNI_neu/Masterarbeit/OTHER/study_behavior_analysis/src/\"\n",
    "path = \"/home/chris/Documents/UNI_neu/Masterarbeit/OTHER/study_behavior_analysis/EducationalResource-2022-01-20.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087db58-c00c-4542-a24f-9bbbe82e9a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def strip_title_description(origdf):\n",
    "    df = origdf.copy()\n",
    "    df[\"description\"] = df[\"description\"].str.strip().str.replace(\"\\r\\n\", \"\\n\") \n",
    "    df[\"description\"] = df[\"description\"].str.replace(\"\\n\\n\", \"\\n\").str.replace(\"\\n\\n\", \"\\n\").str.replace(\"\\n\\n\", \"\\n\").str.replace(\"\\n\\n\", \"\\n\").str.replace(\"\\n\\n\", \"\\n\").str.replace(\"\\n\\n\", \"\\n\").str.replace(\"\\n\\n\", \"\\n\")\n",
    "    df[\"description\"] = df[\"description\"].str.replace(\"\\n\", \" \") \n",
    "    df[\"description\"] = df[\"description\"].str.strip()\n",
    "    df[\"title\"] = df[\"title\"].str.strip()\n",
    "    return df    \n",
    "\n",
    "def groupby_merge(df, by=\"title\"):\n",
    "    \"\"\"INPUT: a dataset with multiple rows per title, each having their own description etc, \n",
    "       OUTPUT: a dataset with unique titles and lists of the original descriptions etc\"\"\"\n",
    "    new_df = []\n",
    "    for num, (title, grouped) in enumerate(df.groupby(by)):\n",
    "        tmp = {}\n",
    "        tmp[by] = title\n",
    "        for col in set(df.columns)-{by}:\n",
    "            tmp[col] = flatten((i if isinstance(i, (list, set, tuple)) else [i]) for i in grouped[col])\n",
    "        new_df.append(tmp)\n",
    "    return pd.DataFrame(new_df)\n",
    "\n",
    "def create_cols(origdf1, origdf2):\n",
    "    \"\"\"this is done as preparation for concatenation to ensure no columns are dropped in the concat\"\"\"\n",
    "    df1, df2 = origdf1.copy(), origdf2.copy()\n",
    "    for column in set(df2.columns)-set(df1.columns):\n",
    "        df1[column] = pd.NA\n",
    "    for column in set(df1.columns)-set(df2.columns):\n",
    "        df2[column] = pd.NA\n",
    "    return df1, df2\n",
    "\n",
    "def make_tuples(origdf, emptynone=False):\n",
    "    \"\"\"lists are not hashable and thus I cannot do stuff like `.unique()` on them \"\"\"\n",
    "    df = origdf.copy()\n",
    "    for col in df.columns:\n",
    "        if isinstance(df[col][0], (list, set)):\n",
    "            if not emptynone:\n",
    "                df[col] = df[col].apply(lambda x:tuple(x))\n",
    "            else: \n",
    "                df[col] = df[col].apply(lambda x: tuple(x) if len(x) > 0 else pd.NA)\n",
    "    return df\n",
    "\n",
    "# filt_de = lambda df: df[df[\"detected_lang\"] == \"de\"]\n",
    "filt_len_single = lambda df: df[df[\"description\"].str.count(\" \") >= 80]\n",
    "filt_len = lambda df, minwords=50: df[df[\"description\"].apply(lambda x: any(i.count(\" \") >= minwords for i in x if not pd.isna(i)))]\n",
    "filt_de = lambda df: df[df[\"detected_lang\"].apply(lambda x: \"de\" in [i for i in x if not pd.isna(i)])]\n",
    "\n",
    "def squeeze_cols(origdf, keep_lists=False, subset=None):\n",
    "    df = origdf.copy()\n",
    "    for col in (subset or df.columns):\n",
    "        if isinstance(df[col][0], (list, set, tuple)):\n",
    "            tmp = df[col].apply(lambda x: unique(i for i in x if not pd.isna(i)) if x is not None else x)\n",
    "            if keep_lists:\n",
    "                tmp = tmp.apply(lambda x: [] if x is None or len(x) == 0 else x)\n",
    "            else:\n",
    "                tmp = tmp.apply(lambda x: pd.NA if x is None or len(x) == 0 else (x[0] if len(x) == 1 else x))\n",
    "            df[col] = tmp\n",
    "    return df\n",
    "\n",
    "def stringify_listcols(origdf):\n",
    "    df = origdf.copy()\n",
    "    for col in df.columns:\n",
    "        if isinstance(df[col][0], (list, set, tuple)):\n",
    "            df[col] = df[col].apply(lambda x: str(x) if len(x) > 0 else \"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f38f9-ae5c-4ffe-8bd9-68c0fd6dcd2e",
   "metadata": {},
   "source": [
    "# First, get the \"EducationalResource-2022-01-20.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b0389d-1182-41ca-952a-c080bb682d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)\n",
    "assert all(i.startswith('\"') and i.endswith('\"') and i[1:-1].isnumeric() for i in df[\"ddc_code\"] if not pd.isna(i))\n",
    "\n",
    "df = strip_title_description(df)\n",
    "df[\"ddc_code\"] = df[\"ddc_code\"].str[1:-1]#.astype(pd.Int64Dtype())\n",
    "df = df.drop(columns=[\"identifier\", \"contributor\", \"creator\", \"coverage\", \"date\", \"rights\", \"relation\"])\n",
    "\n",
    "display(df.describe())\n",
    "print(\"\\n\\n\")\n",
    "display(df.head())\n",
    "print(\"\\n\\n\")\n",
    "display(df[\"origin\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca06a3-d7eb-41c3-80e5-790fb571e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"type\"].unique())\n",
    "df[\"type\"] = df[\"type\"].str.replace(\"['SIP']\", \"SIP\", regex=False).str.replace(\"['udemy', 'mooc']\", \"udemy_mooc\", regex=False).str.replace(\"['OER']\", \"OER\", regex=False)\n",
    "print(df[\"format\"].unique())\n",
    "df[\"format\"] = df[\"format\"].str.replace(\"['CRS']\", \"CRS\", regex=False)\n",
    "df = df.set_index(\"id\")\n",
    "df = df.dropna(subset=[\"title\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b4c56-469d-486f-8c11-351a3912618a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(df[\"publisher\"].value_counts())\n",
    "seldom_publishers = [k for k,v in df[\"publisher\"].value_counts().items() if v <= 20]\n",
    "display(df[df[\"publisher\"].isin(seldom_publishers)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c979df-c68f-40b0-98f2-a9edc60331df",
   "metadata": {},
   "source": [
    "# Next, let's look at \"course_dump_new.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f59b6a-754f-451a-8502-312aaa54c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdn = pd.read_csv(join(BOOK_BASE, \"data/course_data/db_dump_new\", \"course_dump_new.csv\"))\n",
    "cdn = cdn.drop(columns=[\"course_origin_id\", \"place\", \"start_time\", \"end_time\", \"end_semester\", \"date\", \"TF_IDF_scores\",])\n",
    "#display(cdn.head())\n",
    "assert all(i.startswith('\"\\\\\"') and i.endswith('\\\\\"\"') and i[3:-3].isnumeric() for i in cdn[\"ddc_code\"] if not pd.isna(i))\n",
    "cdn[\"ddc_code\"] = cdn[\"ddc_code\"].str[3:-3]\n",
    "cdn = cdn.set_index(\"id\")\n",
    "cdn = strip_title_description(cdn).dropna(subset=[\"title\"])\n",
    "cdn = cdn.rename(columns={\"origin_id\":\"origin\"})\n",
    "\n",
    "print(len(cdn))\n",
    "cdn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70a026-6110-484a-9ba1-a3641d8318ef",
   "metadata": {},
   "source": [
    "# And at \"eduresource_dump.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080557d-d113-48d3-9eb2-c153d36986f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu = pd.read_csv(join(BOOK_BASE, \"data/course_data/db_dump_new\", \"eduresource_dump.csv\"))\n",
    "print(\"#Entries for 'contributor' column:\", len(edu[(~edu[\"contributor\"].isna()) & (~edu[\"contributor\"].isin([[], \"[]\"]))]))\n",
    "print(\"#Entries for 'creator' column:\", len(edu[(~edu[\"creator\"].isna()) & (~edu[\"creator\"].isin([[], \"[]\"]))]))\n",
    "# edu.head()\n",
    "edu = edu.drop(columns=[\"TF_IDF_scores\", \"contributor\", \"date\", \"relation\", \"rights\", \"origin_id\"])\n",
    "display(edu[\"format\"].unique())\n",
    "edu[\"format\"] = edu[\"format\"].str.replace('[\"udemy\", \"mooc\"]', \"udemy_mooc\", regex=False).str.replace('[\"CRS\"]', \"CRS\", regex=False).str.replace('\"video/mp4\"', \"mp4\", regex=False).str.replace('[]', \"\", regex=False)\n",
    "display(edu[\"type\"].unique())\n",
    "edu[\"type\"] = edu[\"type\"].str.replace('[\"SIP\"]', \"SIP\", regex=False).str.replace('[\"udemy\", \"mooc\"]', \"udemy_mooc\", regex=False).str.replace('[\"video\", \"OER\"]', \"video_OER\", regex=False).str.replace('[\"WEB\"]', \"web\", regex=False)\n",
    "display(edu[\"type\"].unique())\n",
    "edu = edu.set_index(\"id\")\n",
    "assert all(i.startswith('\"\\\\\"') and i.endswith('\\\\\"\"') and i[3:-3].isnumeric() for i in edu[\"ddc_code\"] if not pd.isna(i))\n",
    "edu[\"ddc_code\"] = edu[\"ddc_code\"].str[3:-3]\n",
    "edu = strip_title_description(edu).dropna(subset=[\"title\"])\n",
    "print(len(edu))\n",
    "edu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc7bd9-3d69-4032-894c-65ac6d4df0af",
   "metadata": {},
   "source": [
    "## Merging them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f2d8a-1b6a-4a9c-9410-1629732e34b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(len(cdn))\n",
    "print(len(edu))\n",
    "display(df.head(2))\n",
    "display(cdn.head(2))\n",
    "display(edu.head(2))\n",
    "print(list(df.dtypes))\n",
    "print(list(cdn.dtypes))\n",
    "print(list(edu.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9539a51d-c41f-42ec-b299-d9763b3baf48",
   "metadata": {},
   "source": [
    "### merging. First the dumps `df` and `cdn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d95b19b-7ae0-4f09-a18d-6623300c50cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdn[\"type\"] = \"SIP\"\n",
    "cdn[\"dset_origin\"] = \"course_dump_new\"\n",
    "df[\"dset_origin\"] = \"EducationalResource-2022-01-20\"\n",
    "edu[\"dset_origin\"] = \"eduresource_dump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597cef0f-ba23-41d4-9400-2375b341fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(df[\"title\"])), len(set(cdn[\"title\"])), len(set(df[\"title\"])&set(cdn[\"title\"])), len(set(df[\"title\"])|set(cdn[\"title\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd068963-1854-43f3-8cb8-dfa01718692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cdn = create_cols(stringify_listcols(df), stringify_listcols(cdn))\n",
    "df_cdn = groupby_merge(pd.concat([df, cdn]))\n",
    "df_cdn.head()\n",
    "#df_cdn[df_cdn[\"description\"].apply(lambda x: len(x) > 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21fc59d-2b2b-47af-aebb-8219203eecf7",
   "metadata": {},
   "source": [
    "#### merging with edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b660cc52-78f3-483f-a421-bde150a5f924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdn, edu = create_cols(df_cdn, stringify_listcols(edu))\n",
    "df_cdn_edu = groupby_merge(pd.concat([df_cdn, edu]))\n",
    "df_cdn_edu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed32c291-7adf-49e9-8780-1bcfb6071b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 5, 'display.max_columns', 25, 'display.expand_frame_repr', False, 'display.max_colwidth', 20, 'display.float_format', '{:.4f}'.format):\n",
    "    display(df_cdn_edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f404684-c110-47b9-a107-23aecf9b8e73",
   "metadata": {},
   "source": [
    "# Merging with the old one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e02a4c-306d-4f63-b333-5f5a62c33bcb",
   "metadata": {},
   "source": [
    "## Preparing the old one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e28fd5-005e-4e6a-a62e-65f4de0109f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = pd.read_csv(\"/home/chris/Documents/UNI_neu/Masterarbeit/data_new/siddata2021/raw_descriptions.csv\")\n",
    "orig[\"Name\"] = orig[\"Name\"].str.strip()\n",
    "orig[\"Beschreibung\"] = orig[\"Beschreibung\"].str.strip()\n",
    "orig = orig.rename(columns=dict(VeranstaltungsNummer=\"veranstaltungsnummer\", Name=\"title\", Untertitel=\"subtitle\", Beschreibung=\"description\"))\n",
    "orig[\"description\"] = orig[\"description\"].str.strip().str.replace(\"\\r\\n\", \"\\n\")\n",
    "orig[\"description\"] = orig[\"description\"].str.replace(\"\\n\\n\", \"\\n\").str.replace(\"\\n\\n\", \"\\n\").str.replace(\"\\n\\n\", \"\\n\").str.replace(\"\\n\\n\", \"\\n\").str.replace(\"\\n\\n\", \"\\n\").str.replace(\"\\n\\n\", \"\\n\").str.replace(\"\\n\\n\", \"\\n\")\n",
    "orig[\"description\"] = orig[\"description\"].str.replace(\"\\n\", \" \")\n",
    "orig[\"description\"] = orig[\"description\"].str.strip()\n",
    "orig[\"description\"] = orig[\"description\"].str.replace(r'<.*?>', '', regex=True)\n",
    "orig[\"dset_origin\"] = \"old_dump\"\n",
    "orig = strip_title_description(orig)\n",
    "orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb5aa70-9d03-47c8-a30b-7ddd48012161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdn_edu, orig = create_cols(df_cdn_edu, orig)\n",
    "alls = groupby_merge(pd.concat([df_cdn_edu, orig]))\n",
    "alls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa5cec-8a69-49b3-ba0f-0542091b297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alls = alls[alls[\"description\"].apply(lambda x: not all(pd.isna(i) for i in x))] #filter those that have ANY existing description\n",
    "alls = alls.reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e70a32-9526-4097-a599-e29f36625b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alls = squeeze_cols(alls, keep_lists=True)\n",
    "#alls_simple = alls[alls[\"description\"].apply(lambda x: len(x) < 2)].reset_index().drop(columns=\"index\")\n",
    "#alls_multi = alls[~alls[\"description\"].apply(lambda x: len(x) < 2)].reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8745260-dc4f-42e0-9e2c-a1059030c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "alls.to_csv(\"/home/chris/Documents/UNI_neu/Masterarbeit/data_new/siddata2022_again.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3b3f1-cd5e-4503-bc25-7d0bbda763d0",
   "metadata": {},
   "source": [
    "So, we DID SQUEEZE the description. No matter where the course is from, we benefit from more descriptions.\n",
    "So if UOS has a different \"Analysis 1\" Course with a different description than Uni Bremen, good for us, more words in the description for any course of the name \"Analysis 1\".\n",
    "\n",
    "HOWEVER, for everything else, that is not the case and we cannot squeeze! Best example: For the veranstaltungsnummer it is relevant if the course was at UOS or at Bremen, so we must be able to recover which veranstaltungsnummer belonged to which origin, and the easiest for now is to just keep the lists of the same length.  \n",
    "EDIT: this is BS! As shown below, veranstaltungsnummer ONLY EXISTS for the original UOS export!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1001a1e-5220-4093-ab60-d2c3168d4bff",
   "metadata": {},
   "source": [
    "# It's saved. We're done. The rest here is just analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abebe694-be02-4910-aa5f-d0f159812b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7256d0c-c227-4f66-b1ad-7f108cd85210",
   "metadata": {},
   "outputs": [],
   "source": [
    "alls50 = filt_len(alls, minwords=20).reset_index().drop(columns=\"index\")\n",
    "#alls50[\"creator\"].value_counts() is completely empty -> wFe can drop it\n",
    "#any(i > 1 for i in alls50[\"identifier\"][alls50[\"identifier\"].str.len() > 2].value_counts().values) -> identifier is unique, we can drop it\n",
    "alls50 = alls50.drop(columns=[\"creator\", \"identifier\"])\n",
    "alls50 = make_tuples(alls50, emptynone=False)\n",
    "alls50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b785d7ab-3e40-4de8-91b9-b429b7678a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "alls50.loc[:, \"source\"] = None\n",
    "alls50.loc[alls50[\"dset_origin\"].apply(lambda x: \"old_dump\" in x), \"source\"] = \"2021 Dump\"\n",
    "alls50.loc[alls50[\"dset_origin\"].apply(lambda x: not \"old_dump\" in x and \"course_dump_new\" in x), \"source\"] = \"2022 Dump\"\n",
    "alls50.loc[alls50[\"dset_origin\"].apply(lambda x: not \"old_dump\" in x and not \"course_dump_new\" in x), \"source\"] = \"Educational-Resources\"\n",
    "\n",
    "with PdfPages(\"/home/chris/Documents/UNI_neu/Masterarbeit/MastersThesisText/graphics/dataset_new/course_source_df.pdf\") as pdf:\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(alls50[\"source\"].value_counts().values, labels=alls50[\"source\"].value_counts().index, autopct=lambda p: '{:.0f}'.format(p * len(alls50) / 100))\n",
    "    ax1.axis('equal')\n",
    "    plt.show()\n",
    "    pdf.savefig(fig1, bbox_inches='tight')\n",
    "\n",
    "alls50 = alls50.drop(columns=\"dset_origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e92c62-3b9f-4d78-8d98-2bb1723017b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(alls50[(alls50[\"source\"] != \"2021 Dump\") & (alls50[\"veranstaltungsnummer\"].apply(lambda x: len(x) > 1))]) == 0 \n",
    "#veranstaltungsnummer ONLY EXISTS for the original UOS export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0545db8b-6c30-4914-b28e-c52e78fa0d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alls50[\"type\"] = alls50[\"type\"].apply(lambda x: x[0] if not pd.isna(x) and len(x) > 0 else pd.NA)\n",
    "#there is one single entity that has two types, we'll just ignore that.\n",
    "alls50.loc[alls50[\"source\"] == \"2021 Dump\", \"type\"] = \"SIP\"\n",
    "\n",
    "tmp = alls50[[\"source\", \"type\"]].reset_index().drop(columns=\"index\")\n",
    "tmp[\"type\"] = tmp[\"type\"].fillna(\"unknown\")\n",
    "count_df = pd.DataFrame(tmp.value_counts(dropna=False)).rename(columns={0:\"Count\"})\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d15fc-e7ae-4673-8247-5c382234c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.sunburst(count_df.reset_index(), path=['source', 'type'], values=\"Count\")\n",
    "fig.update_traces(textinfo=\"label+value\") # Any combination of [‘label’, ‘text’, ‘value’, ‘current path’, ‘percent root’, ‘percent entry’, ‘percent parent’] \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b535ba-f39b-4a4b-9acf-e3cf244b4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "trnsl = {\"f6f8ced1-2a20-45de-ad27-46297617f247\": \"de.uni-hannover.studip\", \"8f83372d-7e8a-4720-bd63-90572e8a3d26\": \"de.uni-osnabrueck.studip\", \"1cf496ff-6e14-4c3b-89fc-304c974cfe8c\": \"de.uni-bremen.elearning\"}\n",
    "tmp = alls50[[\"publisher\", \"origin\"]]\n",
    "tmp = tmp.dropna()\n",
    "tmp[\"origin\"] = tmp[\"origin\"].apply(lambda x: tuple(trnsl.get(i, i) for i in x if not pd.isna(i)))\n",
    "tmp[\"default_publisher\"] = tmp[\"publisher\"].apply(lambda x: any(i == \"default\" for i in x if not pd.isna(i)))\n",
    "tmp[\"publisher\"] = tmp[\"publisher\"].apply(lambda x: tuple(i for i in x if not pd.isna(i) and i != \"default\"))\n",
    "\n",
    "tmp = tmp[tmp[\"publisher\"] != tmp[\"origin\"]]\n",
    "#print(\"So many ones have a differing origin and publisher:\", len(tmp))\n",
    "#display(tmp.head())\n",
    "\n",
    "overwrite_publisher = {n: sorted(list(set(i[\"publisher\"])|set(i[\"origin\"])|({\"default\"} if i[\"default_publisher\"] else set()))) for n,i in tmp.iterrows()}\n",
    "for ind, publisher in overwrite_publisher.items():\n",
    "    alls50.loc[ind, \"publisher\"] = publisher\n",
    "    \n",
    "\n",
    "#those of the 2021 dump don't mention it, but their publisher is osnabrueck.\n",
    "alls50.loc[alls50[\"source\"] == \"2021 Dump\", \"publisher\"] = alls50.loc[alls50[\"source\"] == \"2021 Dump\", \"publisher\"].fillna(\"de.uni-osnabrueck.studip\").apply(lambda x: x if \"de.uni-osnabrueck.studip\" in x else tuple(sorted(list(x)+[\"de.uni-osnabrueck.studip\"])))\n",
    "alls50[\"publisher\"] = alls50[\"publisher\"].apply(lambda x: tuple([x]) if isinstance(x, str) else x)\n",
    "alls50 = alls50.drop(columns=\"origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60ca928-3fb4-48bf-95b4-6d7853fb1668",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in trnsl.values():\n",
    "    alls50[f\"is_{val}\"] = alls50[\"publisher\"].apply(lambda x: val in x)\n",
    "alls50[\"is_other\"] = alls50[\"publisher\"].apply(lambda x: len(set(i for i in x if i not in trnsl.values()))>0)\n",
    "alls50 = alls50.rename(columns={\"is_de.uni-hannover.studip\": \"is_hannover\", \"is_de.uni-osnabrueck.studip\": \"is_uos\", \"is_de.uni-bremen.elearning\": \"is_bremen\"}).drop(columns=\"publisher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3e165-d2c8-469f-b17d-5982658ab2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alls50[\"format\"] = alls50[\"format\"].apply(lambda x: x if x != (\"CRS\", \"udemy_mooc\") else (\"CRS+mooc\",))\n",
    "assert not any(alls50[\"format\"].apply(lambda x: len(x) > 1))  #there is no course with >1 format\n",
    "alls50[\"format\"] = alls50[\"format\"].apply(lambda x: pd.NA if len(x) == 0 else x[0])\n",
    "alls50.loc[alls50[\"format\"] == \"\", \"format\"] = pd.NA\n",
    "alls50.loc[alls50[\"type\"] == \"SIP\", \"format\"] = \"CRS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb89c3e-9792-4422-823a-87971240143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_temp = alls50[\"subject\"].apply(lambda x: [i for i in x if not (pd.isna(i) or i in [[],\"[]\"])])\n",
    "alls50[\"subject\"] = subject_temp.apply(lambda x: pd.NA if len(x) == 0 else flatten([eval(i) for i in x]))\n",
    "#alls50[\"subject\"].dropna()[228] # PERFECT KEYWORD-CANDIDATES!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9d178-887c-4c00-a1a0-c35e65530a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alls50.loc[alls50[\"coverage\"].apply(lambda x: len(x) > 1),\"coverage\"] = alls50[alls50[\"coverage\"].apply(lambda x: len(x) > 1)][\"coverage\"].apply(lambda x: (\",\".join(x),))\n",
    "#sind bei len>=20 nur 3 stück, die appenden wir einfach, fertig.\n",
    "\n",
    "assert list(dict(alls50[\"coverage\"].apply(lambda x: len(x)).value_counts()).keys()) == [0, 1] #there is no course with > coverage\n",
    "alls50[\"coverage\"] = alls50[\"coverage\"].apply(lambda x: pd.NA if len(x) == 0 else x[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18479d6-d466-4eb7-b566-7d0c695df976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only languages I see are de & en\n",
    "lans = alls50[\"language\"].apply(lambda x: unique([j.replace(\"Deutsch\",\"de\").replace(\"English\",\"en\") for j in flatten([i.split(\",\") for i in x])]))\n",
    "alls50[\"language\"] = lans.apply(lambda x: pd.NA if len(x) == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fb5472-570f-4cdf-8c68-b7c573d73520",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len([i for i in alls50[\"coverage\"].unique() if not pd.isna(i)]) == 0\n",
    "alls50 = alls50.drop(columns=\"coverage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca34a26-15f3-4e07-811d-bfe332c38bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"ddc_code\", \"start_semester\", \"url\"]:\n",
    "    alls50[col] = alls50[col].apply(lambda x: pd.NA if len(x) == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbbab6b-c5c3-4f7d-9711-aafb835d90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alls50[alls50[\"type\"].isna()]) <= 10\n",
    "alls50 = alls50[~alls50[\"type\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799feac2-97c1-4a1e-91cc-e427145f3923",
   "metadata": {},
   "outputs": [],
   "source": [
    "alls50.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19a6144-10bf-4501-b6a9-d5b5b7563177",
   "metadata": {},
   "source": [
    "Ok, das reicht uns erstmal.\n",
    "* **title, description, language** sind klar.\n",
    "* **format, type, source**  sind meta-infos, die aber nur für wenige gegeben sind.\n",
    "* **subject** sind lists of keywords for the course. PERFECT to add to the description AND to automatically take as keyword-candidates!!\n",
    "* **subtitle** kann man optional zu den descriptions adden und dann behandeln wie eine descriptions.\n",
    "* **ddc_code, veransltaltungsnummer**  sind possible targets (!)\n",
    "* **is_hannover, is_bremen, ...** sind auch possible targets\n",
    "* **start_semester, url** sind for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee509c13-ea8b-4f50-ae80-23df93c570c9",
   "metadata": {},
   "source": [
    "## Okay, I'll translate them now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46de2b3-5b27-4dc7-87bf-d35345153456",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_descs = alls50[\"description\"].explode().dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc30cf-6616-4597-8ca5-a195cd893697",
   "metadata": {},
   "outputs": [],
   "source": [
    "lans = get_langs(unique_descs, assert_len=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511ea9a-180f-4258-be83-53f77c70416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = alls50[alls50[\"description\"].apply(lambda x:len(set(lans[i] for i in x)) > 1)]\n",
    "arg = pd.DataFrame(arg[[\"title\", \"description\"]].explode(\"description\"))\n",
    "arg[\"lang\"] = arg[\"description\"].apply(lambda x: lans[x])\n",
    "with pd.option_context('display.max_rows', 5, 'display.max_colwidth', 4000):\n",
    "    display(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354bf9e1-8219-4f9d-b4b5-be4086871a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alls50[\"detected_lang\"] = alls50[\"description\"].apply(lambda x:set(lans[i] for i in x))\n",
    "display(alls50[\"detected_lang\"].apply(lambda x: \"de\" if \"de\" in x else list(x)[0]).value_counts()[:5])\n",
    "alls50[\"detected_lang\"] = alls50[\"detected_lang\"].apply(lambda x: \"de\" if \"de\" in x else (\"en\" if \"en\" in x else \"other\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806f3f2-5c72-4a24-b61b-3c3af12f78bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e375bd7c-6dbe-4713-8d99-c3e82afe1e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = alls50.copy()\n",
    "tmp[\"format\"] = tmp[\"format\"].fillna(\"unknown\")\n",
    "tmp[tmp[\"format\"] == \"CRS+mooc\"] = \"udemy_mooc\"\n",
    "tmp[\"type\"] = tmp[\"type\"].fillna(\"unknown\")\n",
    "tmp[\"is_uos\"] = tmp[\"is_uos\"].apply(lambda x: \"UOS\" if x else \"other\")\n",
    "count_df = pd.DataFrame({f\"Count≥{x}\": filt_len(tmp, x)[[\"source\", \"type\", \"format\", \"is_uos\", \"detected_lang\"]].value_counts(dropna=False) for x in [20, 50, 200, 500]}).sort_index()\n",
    "count_df.style.format(precision=0, na_rep=\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ba3a6-2789-422b-9a2b-7976680ed0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df.index.names = [i.capitalize() for i in count_df.index.names]\n",
    "styles = [{'selector': 'th', 'props': [('vertical-align','top')]}]  #('border-style', 'solid')  #see https://stackoverflow.com/a/55904239/5122790\n",
    "styler = lambda df: df.style.format(precision=0, na_rep=\"-\").set_table_styles(styles)\n",
    "latex = df_to_latex(count_df, styler, rotate=None)\n",
    "latex = latex.replace(\"Is_uos\", \"Uni\").replace(\"Detected_lang\", \"Language\").replace(\"udemy_mooc\", \"Udemy-\\\\acrshort{mooc}\").replace(\"Count\", \"\\#Words\").replace(\"UOS\",\"\\\\acrshort{uos}\")\n",
    "#latex = latex.replace(\"\\\\textbf{Educational-Resources}\", \"\\\\specialcell[l]{\\\\textbf{Educational\\\\\\\\Resources}}\")\n",
    "\n",
    "pyperclip.copy(latex)\n",
    "#caption: \"\\caption[Metadata of the SIDDATA-Dataset]{Metadata of the SIDDATA-Dataset. Languages are reported as detected (see \\ref{ap:translating}), other metadata as it was available in the dump. The individual columns is the number of entities whose description has at least 20, 50, 200 or 500 words.}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a435e42-fcf4-441c-94ff-398d60b67901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(count_df.index.names)):\n",
    "    display(count_df.sum(axis=0, level=i).style.format(precision=0, na_rep=\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9716b72c-859d-417e-a2bb-cc67aaf4ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.sunburst(count_df.reset_index(), path=count_df.index.names, values=\"Count≥50\")\n",
    "fig.update_traces(textinfo=\"label+value\") # Any combination of [‘label’, ‘text’, ‘value’, ‘current path’, ‘percent root’, ‘percent entry’, ‘percent parent’] \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92dc4ad-988d-4ade-b4f7-c4d2655ed94b",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f2b943-65ea-4fe4-bcee-9857ab805eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "alls50.to_csv(\"/home/chris/Documents/UNI_neu/Masterarbeit/data_new/siddata2022_again.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
