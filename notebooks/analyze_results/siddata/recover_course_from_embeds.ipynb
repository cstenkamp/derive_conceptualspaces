{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c4bcd7-3c78-4eee-87f7-e43f8decd338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from derive_conceptualspace.evaluate.shallow_trees import classify_shallowtree\n",
    "from derive_conceptualspace.pipeline import SnakeContext, load_envfiles\n",
    "from derive_conceptualspace.util.result_analysis_tools import get_best_conf\n",
    "from derive_conceptualspace.cli.args_from_filename import get_filename, print_envvars\n",
    "from misc_util.logutils import setup_logging\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084b8a0-a457-4164-9af6-93cc95e27841",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging()\n",
    "load_envfiles(\"siddata\")\n",
    "conf, perf = get_best_conf(\"fachbereich\", verbose=True, balance_classes=True, one_vs_rest=True, dt_depth=1, test_percentage_crossval=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476fcf3-e378-4458-b417-8810ffcfa43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_envvars(get_filename(conf, get_dependencies=False, doprint=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741276b1-44a9-454a-a299-ea562840ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = SnakeContext.loader_context(config=conf, silent=True, warn_filters=[\"DifferentFileWarning\"])\n",
    "ctx.print_important_settings()\n",
    "cluster_reprs, clusters, embedding, descriptions = ctx.load(\"cluster_reprs\", \"clusters\", \"embedding\", \"pp_descriptions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeaa9c5-34e6-4b26-9019-21f3fe14411a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Detected Semantic Directions:\", \", \".join(list(cluster_reprs.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63393c87-0f4d-454e-b630-2ae7c47b18f9",
   "metadata": {},
   "source": [
    "## Can we recover the exact courses from the detected directions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f14fa-a824-4209-9469-fd6e1c17c7e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "from derive_conceptualspace.util.result_analysis_tools import df_to_latex\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "from misc_util.pretty_print import pretty_print as print\n",
    "from derive_conceptualspace.semantic_directions.cluster_names import get_name_dict\n",
    "clus_rep_algo = \"top_1\"\n",
    "clusters, planes = clusters.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ef322-35f1-4678-8c23-9f199c5fbfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_names = get_name_dict(clusters, cluster_reprs, clus_rep_algo)\n",
    "#first I want the distances to the origins of the respective dimensions (induced by the clusters), what induces the respective rankings (see DESC15 p.24u, proj2 of load_semanticspaces.load_projections)\n",
    "axis_dists = {i: {cluster_names[k]: v.dist(embedding[i]) for k, v in planes.items()} for i in range(len(embedding))}\n",
    "best_per_dim = {k: descriptions._descriptions[v].title for k, v in pd.DataFrame(axis_dists).T.idxmax().to_dict().items()}\n",
    "print(\"Highest-ranking descriptions [with any class] per dimension:\\n    \"+\"\\n    \".join([f\"*b*{k.ljust(max([len(i) for i in best_per_dim.keys()][:20]))}*b*: {v}\" for k, v in best_per_dim.items()][:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551e6fd-5f81-48f7-a871-86ba32c161b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO also show places 2, 3, 4 - hier sehen wir wieder sehr Ã¤hnliche (\"football stadium\", \"stadium\", \"fan\" for \"goalie\")\n",
    "#TODO axis_dists is all I need for the movietuner already!! I can say \"give me something like X, only with more Y\"\n",
    "\n",
    "consider = pd.DataFrame({descriptions._descriptions[i].title: axis_dists[i] for i in range(len(embedding))})\n",
    "ranked = pd.DataFrame([rankdata(i) for i in consider.values], index=consider.index, columns=consider.columns).astype(int).T\n",
    "ranked = ranked / ranked.shape[0] #looks better if we're doing relative rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8daf41-32c6-4f4c-9223-d70fa2f7c2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 10, 'display.max_columns', 10, 'display.expand_frame_repr', False, 'display.float_format', '{:.3f}'.format):\n",
    "    display(ranked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a5e0b-d40d-4da0-a8d0-7f66ee690d08",
   "metadata": {},
   "source": [
    "So now we will test if we can recover one specific course perfectly against all others with a decision tree...\n",
    "\n",
    "* With the rankings in the semantic directions rounded\n",
    "* With only a random subset of the semanatic directions.\n",
    "\n",
    "In every `repeat`, we will test `ntests` random candidates with only `max_dirs` randomly selected directions, rounded to `roundto`. Which directions to select differs in every `repeat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212304e-d477-4483-8707-5349025de8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_recover_one(ranked, roundto=3, ntests=100, max_dirs=None, repeat=1):\n",
    "    repeat_results = []\n",
    "    with tqdm(total=ntests*repeat, leave=False) as pgbar:\n",
    "        for ntrial in range(repeat):\n",
    "            clone = ranked.copy().round(roundto)\n",
    "            if max_dirs:\n",
    "                clone = clone[np.random.choice(clone.columns, max_dirs)]\n",
    "            results = []\n",
    "            for i in np.random.choice(range(len(clone)), ntests):\n",
    "                targets = [0]*len(clone)\n",
    "                targets[i] = 1\n",
    "                clf = DecisionTreeClassifier()\n",
    "                clf.fit(clone.values, targets)\n",
    "                results.append((clf.predict(clone.values) == targets).all())\n",
    "                pgbar.update(1)\n",
    "                \n",
    "            repeat_results.append(sum(results)/len(results))\n",
    "        return repeat_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28de278-4aff-4c27-87eb-05e4a2e6a32c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REPEAT = 20\n",
    "NTESTS = 200\n",
    "\n",
    "ROUND_TO = [3, 2, 1]\n",
    "MAX_DIRS = [150, 100, 50, 20, 10, 5, 3]\n",
    "\n",
    "n=0\n",
    "results = {}\n",
    "for roundto in ROUND_TO:\n",
    "    for max_dirs in MAX_DIRS:\n",
    "        n += 1\n",
    "        print(f\"Run {n}/{len(ROUND_TO)*len(MAX_DIRS)}. Arguments: round-to={roundto}, max-dirs={max_dirs}\")\n",
    "        res = test_recover_one(ranked, roundto=roundto, ntests=NTESTS, max_dirs=max_dirs, repeat=REPEAT)\n",
    "        print(f\"   Mean Accuracy: {np.array(res).mean():.2%}, Standard-Deviation: {np.array(res).std():.4f}, Best Result: {np.array(res).max():.2%}\")\n",
    "        results[(roundto,max_dirs)] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd4ce89-d802-40ff-815a-b704ff8c8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = [{'selector': 'th', 'props': [('vertical-align','top'),('text-align','left')]}]  #('border-style', 'solid')\n",
    "styler = lambda df: df.style.format('{:.2%}'.format).set_table_styles(styles) #{\"amax\": '{:.0%}'.format, \"mean\": '{:.2%}'.format}\n",
    "\n",
    "df = pd.DataFrame(results, columns=pd.MultiIndex.from_arrays(list(zip(*results.keys())), names=[\"Precision\", \"Max-Dims\"]))\n",
    "df = df.agg([np.max, np.mean])  #, np.std\n",
    "df = df.T.sort_index().T\n",
    "styler(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec593001-ebc5-49a7-a91a-f79d7eb331bd",
   "metadata": {},
   "source": [
    "With three **random** directions we can on average recover 95% of courses!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5051ae2-b05e-4513-a2a7-aec0eb109b7d",
   "metadata": {},
   "source": [
    "## We don't even need to use classifiers, we can just look at the number of duplicates dependent on the number and precision of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46936e54-2983-4bb9-bbf0-2448a07b91d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dups(ranked, digit_bins, max_dirs, noise_lvl=(0,), repeat=1):\n",
    "    total = len(digit_bins) * len(max_dirs) * len(noise_lvl) * repeat\n",
    "    with tqdm(total=total) as pgbar:\n",
    "        res = {}\n",
    "        for bins in digit_bins:\n",
    "            for dirs in max_dirs:\n",
    "                for noise in noise_lvl:\n",
    "                    dup_num, dup_in = [], []\n",
    "                    for ntrial in range(repeat):\n",
    "                        clone = ranked.copy()\n",
    "                        clone = clone[np.random.choice(clone.columns, dirs, replace=False)]\n",
    "                        clone += np.random.normal(0, noise, clone.values.shape)\n",
    "                        clone = clone.apply(lambda x: np.digitize(x, bins=np.linspace(0, 1, bins)))\n",
    "                        \n",
    "                        n_dups = clone.groupby(clone.columns.tolist()).size()\n",
    "                        dup_num.append(n_dups[n_dups > 1].sum())\n",
    "                        dup_in.append(n_dups[n_dups > 1].count())\n",
    "                        pgbar.update(1)\n",
    "                    res[(bins, dirs, noise)] = dict(value_space=min(bins**dirs, 2**99),\n",
    "                                                    dup_num_max=np.array(dup_num).max(), dup_num_mean=np.array(dup_num).mean(), \n",
    "                                                    dup_in_max=np.array(dup_in).max(), dup_in_mean=np.array(dup_in).mean())\n",
    "                    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9256e1-6310-4bfd-aa98-f4274cdfda36",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = [len(clone)//5000, len(clone)//1000, len(clone)//500, len(clone)//100,  len(clone)//50, len(clone)//10]\n",
    "ndims = [3, 5, 10, 20, 50, 100, 200]\n",
    "noise = [0]\n",
    "\n",
    "res = count_dups(ranked, nbins, ndims, noise_lvl=noise, repeat=20)\n",
    "#display(pd.DataFrame(res, columns=pd.MultiIndex.from_arrays(list(zip(*res.keys())), names=[\"#bins\", \"#dims\", \"noise\"])))\n",
    "res = {k: dict(value_fill = v[\"dup_in_mean\"]/v[\"value_space\"], dup_perc = v[\"dup_num_mean\"]/len(clone)) for k, v in res.items()}\n",
    "\n",
    "styles = [{'selector': 'th', 'props': [('vertical-align','top'),('text-align','left')]}]  \n",
    "styler = lambda df: df.style.format('{:.2%}'.format).set_table_styles(styles) \n",
    "df = pd.DataFrame(res, columns=pd.MultiIndex.from_arrays(list(zip(*res.keys())), names=[\"#bins\", \"#dims\", \"noise\"]))\n",
    "styler(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae659da-8204-44c6-9186-4da307723903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({k[:2]:v[\"dup_perc\"] for k,v in res.items()}, columns=pd.MultiIndex.from_arrays(list(zip(*res.keys()))[:2], names=[\"#bins\", \"#dims\"]), index=[\"dup_perc\"])\n",
    "df = df.T.unstack(level=[0])\n",
    "styler(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c90fb6-ce41-4f2f-bdb3-17ec88e5e72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy(df_to_latex(df, styler, rotate=False, caption=\"This algorithm on Placetypes\"), multi_ind=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ea80a-e999-4a6f-9b9c-633a48ebba5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1572d7ef-3ea5-4a0b-86dc-7e452cd84e7b",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4fb7c-06c1-47fd-bcf8-eaaaa05da2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "862a3efc-4ac6-4b84-8196-0c2cddd15c36",
   "metadata": {},
   "source": [
    "## Analyzing what becomes duplicates may reveal actual duplicate courses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0b1561-d676-4868-ab6f-692336ea2202",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dirs, digit_bins = 3, len(clone)//500\n",
    "print(\"n-cats:\", digit_bins)\n",
    "res = []\n",
    "for _ in range(100):\n",
    "    targets = [0]*len(clone)\n",
    "    targets[i] = 1\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(clone.values, targets)\n",
    "    result = clf.predict(clone.values)\n",
    "    res.append((result == targets).all())\n",
    "np.array(res).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc69aba-c16c-49d2-9e14-89b1d5049063",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dups = clone.groupby(clone.columns.tolist()).size()\n",
    "dup_num, dup_in = n_dups[n_dups > 1].sum(), n_dups[n_dups > 1].count()\n",
    "print(f\"Duplicates: {dup_num} ({dup_num/len(clone):.2%}) entities share {dup_in} values (value-space {dup_in/(digit_bins**max_dirs):.2%} filled)\")\n",
    "\n",
    "display(clone[(clone == (clone.iloc[np.argmax(np.array(targets))].values)).all(axis=1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
