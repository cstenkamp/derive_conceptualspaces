{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from textwrap import shorten \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "\n",
    "from misc_util.logutils import setup_logging\n",
    "from misc_util.pretty_print import display\n",
    "\n",
    "from derive_conceptualspace.pipeline import SnakeContext, load_envfiles\n",
    "from derive_conceptualspace.settings import DEFAULT_N_CPUS\n",
    "from derive_conceptualspace.util.result_analysis_tools import getfiles_allconfigs\n",
    "from derive_conceptualspace.util.threadworker import WorkerPool\n",
    "from derive_conceptualspace.analysis.plots import scatter_2d, scatter_3d, set_seaborn\n",
    "from derive_conceptualspace.util.threedfigure import ThreeDFigure\n",
    "from derive_conceptualspace.util.base_changer import ThreeDPlane, make_base_changer\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Data-Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging()\n",
    "load_envfiles(\"siddata\")\n",
    "configs, print_cnf = getfiles_allconfigs(\"clusters\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with WorkerPool(DEFAULT_N_CPUS-1, pgbar=\"Fetching clusters..\") as pool:\n",
    "    get_featureaxes = lambda conf: ((ctx := SnakeContext.loader_context(config=conf, silent=True)).get_important_settings(), ctx.load(\"clusters\"), conf)\n",
    "    perconf_list, interrupted = pool.work(configs, get_featureaxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_conf(perconf_list, restrictions=None):\n",
    "    restrictions = restrictions or (lambda x: True)\n",
    "    perconf_list = [elem for elem in perconf_list if restrictions(elem[2])]\n",
    "    print(\"Number of clusters per config:\", [len(x[1][\"clusters\"]) for x in perconf_list])\n",
    "    display(\"Taking one of the configs with the most clusters...\")\n",
    "    settings_str, clusters, conf = max(perconf_list, key=lambda x: len(x[1][\"clusters\"]))\n",
    "    display(settings_str[1])\n",
    "    display(\"Loading the rest of the necessary config...\")\n",
    "    ctx, (embedding, descriptions, dissim_mat) = (ctx := SnakeContext.loader_context(config=conf, silent=True)), ctx.load(\"embedding\", \"pp_descriptions\", \"dissim_mat\")\n",
    "    display(\"loading done.\")\n",
    "    return ctx, embedding, descriptions, dissim_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting original 3D-Embeddings\n",
    "\n",
    "* The following plot visualizes an unaltered 3-dimensional MDS Embedding as it was created in the algorithm\n",
    "* 3D Plot is interactive! You can twist & turn and also disable & enable individual categories using the legend!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx, embedding, descriptions, dissim_mat = load_best_conf(perconf_list, restrictions=lambda x: x[\"embed_dimensions\"] == 3)\n",
    "getcat, hascat, catnames = ctx.obj[\"dataset_class\"].get_custom_class(\"fachbereich\", descriptions)\n",
    "embedding = embedding[hascat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.column_stack((embedding, [getcat(i) for i in hascat])), columns=[\"x\",\"y\",\"z\",\"faculty\"], index=hascat)\n",
    "scatter_3d(df, \"faculty\", catnames, descriptions=descriptions);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/>\n",
    "## Plotting the result of t-SNE of the best-performing dissimilarity Matrix\n",
    "\n",
    "...Dissimiliarity-Matrix, not Embedding! t-SNE is doing the embedding here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx, embedding, descriptions, dissim_mat = load_best_conf(perconf_list)\n",
    "getcat, hascat, catnames = ctx.obj[\"dataset_class\"].get_custom_class(\"fachbereich\", descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissim_mat = dissim_mat[1][hascat].T[hascat].T\n",
    "# tsne_emb = TSNE(n_components=2, random_state=0, metric=\"cosine\"); tsne_emb.fit(embedding) #we could also do TSNE on the embedding here\n",
    "tsne_emb = TSNE(n_components=2, random_state=0, metric=\"precomputed\")\n",
    "tsne = tsne_emb.fit(dissim_mat)\n",
    "df = pd.DataFrame(np.column_stack((tsne.embedding_, [getcat(i) for i in hascat])), columns=[\"x\",\"y\",\"faculty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = join(ctx.p.in_dir, f\"scatter_mds_tsne_{ctx.get_important_settings()[0][3:-3]}.pdf\")\n",
    "set_seaborn()\n",
    "with PdfPages(savepath) as pdf:\n",
    "    fig = scatter_2d(df, \"faculty\", catnames)\n",
    "    pdf.savefig(fig, bbox_inches='tight')\n",
    "print(f\"Saved under {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>\n",
    "\n",
    "# Plotting 1-vs-Rest on the 3D MDS Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_allagainst = \"Sprach-/Literaturwissenschaften\"\n",
    "\n",
    "ctx, embedding, descriptions, dissim_mat = load_best_conf(perconf_list, restrictions=lambda x: x[\"embed_dimensions\"] == 3)\n",
    "getcat, hascat, catnames = ctx.obj[\"dataset_class\"].get_custom_class(\"fachbereich\", descriptions)\n",
    "embedding = embedding[hascat]\n",
    "\n",
    "df = pd.DataFrame(np.column_stack((embedding, [getcat(i) for i in hascat])), columns=[\"x\",\"y\",\"z\",\"faculty\"], index=hascat)\n",
    "df[\"faculty\"] = df[\"faculty\"] == {v: k for k, v in catnames.items()}[plot_allagainst]\n",
    "# scatter_3d(df, \"faculty\", {True: plot_allagainst, False: \"Other\"}, descriptions=descriptions, name=f\"3D-Embedding, One vs Rest: {plot_allagainst}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"faculty\"\n",
    "svm = sklearn.svm.LinearSVC(class_weight=\"balanced\", loss=\"hinge\", max_iter=20000)\n",
    "emb = df[[\"x\",\"y\",\"z\"]].values\n",
    "svm.fit(emb, df[category])\n",
    "decision_plane = ThreeDPlane(svm.coef_[0], svm.intercept_[0])\n",
    "forward, backward = make_base_changer(decision_plane)\n",
    "\n",
    "prototypicality_pre = lambda x: abs(forward(x)[0])\n",
    "all_prototyp = [prototypicality_pre(emb[i]) for i in range(len(emb))]\n",
    "prototypicality = lambda x: round(((prototypicality_pre(x)-min(all_prototyp))/(max(all_prototyp)-min(all_prototyp)))*100, 2)\n",
    "\n",
    "catnames = {True: plot_allagainst, False: \"Other\"}\n",
    "FACTOR = 0.4\n",
    "\n",
    "with ThreeDFigure(width=1120, name=f\"3D-Embedding, One vs Rest: {plot_allagainst}\", bigfont=True) as fig:  #forward, backward, swap_axes=\"xz\"\n",
    "    for ncol, part_df in enumerate(set(df[category])):\n",
    "        emb = df[df[category] == part_df]\n",
    "        if descriptions is not None:\n",
    "            descs = [descriptions._descriptions[i] for i in list(df[df[category] == part_df].index)]\n",
    "            custom_data = [{\"Name\": desc.title, \"V.Nr.\": \"|\".join(eval(desc._additionals[\"veranstaltungsnummer\"])),\n",
    "                \"Prototypicality\": round(prototypicality(emb[[\"x\", \"y\", \"z\"]].iloc[n].values), 2),\n",
    "                \"Class\": catnames[emb.iloc[n][category]] if catnames else emb.iloc[n][category],  \"extra\": {\"Description\":shorten(desc.text, 200) }} for n, desc in enumerate(descs)]\n",
    "        fig.add_markers(emb[[\"x\", \"y\", \"z\"]].values, name=catnames[part_df] if catnames else part_df, color=ncol, size=1.5, custom_data=custom_data)\n",
    "        \n",
    "    vals = df[[\"x\", \"y\", \"z\"]].values\n",
    "    fig.add_surface(decision_plane, vals, df[category], margin=0.1, color=\"lightblue\", showlegend=True, name=\"Decision Plane\")\n",
    "    fig.add_line(vals.mean(axis=0)-decision_plane.normal*FACTOR, vals.mean(axis=0)+decision_plane.normal*FACTOR, width=5, name=\"Decision Plane Orthogonal\") \n",
    "#     fig.add_markers([0, 0, 0], size=3, name=\"Coordinate Center\") \n",
    "    \n",
    "    fig.fig.update_layout(legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_results = svm.predict(df[[\"x\",\"y\",\"z\"]].values)\n",
    "# correct_preds = [df[category].iloc[i] == (svm_results[i] > 0) for i in range(len(svm_results))]\n",
    "# display(f\"Accuracy of the SVM: {sum(correct_preds)/len(correct_preds):.1%}\")\n",
    "conf_mat = sklearn.metrics.confusion_matrix(y_true=df[category], y_pred=svm_results)\n",
    "tn, fp, fn, tp = conf_mat.ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "accuracy = (tp + tn) / len(svm_results)\n",
    "display(f\"Accuracy: {accuracy:.1%} | Precision: {precision:.1%} | Recall: {recall:.1%}\")\n",
    "\n",
    "display(f\"Elements per Class: {dict(Counter([catnames[i] for i in df[category]]))}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "display_labels = [i[1].replace(\"/\",\"/\\n\") for i in sorted(catnames.items(), key=lambda x: x[0])]\n",
    "plot = sklearn.metrics.ConfusionMatrixDisplay.from_estimator(svm, X=df[[\"x\",\"y\",\"z\"]].values, y=df[category], display_labels=display_labels, ax=ax, xticks_rotation=\"horizontal\");\n",
    "for item in ([ax.title] + ax.get_xticklabels() + ax.get_yticklabels()): # ax.xaxis.label, ax.yaxis.label\n",
    "    item.set_fontsize(12)\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies for all Faculties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "getcat, hascat, catnames = ctx.obj[\"dataset_class\"].get_custom_class(\"fachbereich\", descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs, f1s = {}, {}\n",
    "for facnum, faculty in catnames.items():\n",
    "    df = pd.DataFrame(np.column_stack((embedding, [getcat(i) for i in hascat])), columns=[\"x\",\"y\",\"z\",\"faculty\"], index=hascat)\n",
    "    df[\"faculty\"] = df[\"faculty\"] == facnum\n",
    "    svm = sklearn.svm.LinearSVC(class_weight=\"balanced\", loss=\"hinge\", max_iter=200000)\n",
    "    emb = df[[\"x\",\"y\",\"z\"]].values\n",
    "    svm.fit(emb, df[\"faculty\"])\n",
    "    svm_results = svm.predict(df[[\"x\",\"y\",\"z\"]].values)\n",
    "#     print(f\"{faculty.rjust(max(len(i) for i in catnames.values()))}: Accuracy {accuracy_score(df[category], svm_results):.3f}, F1 {f1_score(df[category], svm_results):.3f}\")\n",
    "    accs[faculty] = accuracy_score(df[category], svm_results)\n",
    "    f1s[faculty] = f1_score(df[category], svm_results)\n",
    "\n",
    "    \n",
    "df = pd.concat([\n",
    "    pd.DataFrame(accs, index=[\"accuracy\"]),\n",
    "    pd.DataFrame(f1s, index=[\"f1\"]),\n",
    "    pd.DataFrame(Counter([catnames[getcat(i)] for i in hascat]), index=[\"count\"])\n",
    "]).T\n",
    "tmp = df.mean(axis=0)\n",
    "df.loc[\"weighted_mean\"] = (df[[\"accuracy\", \"f1\"]].multiply(df[\"count\"]/df[\"count\"].sum(), axis=0)).sum()\n",
    "df.loc[\"unweighted_mean\"] = tmp\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
