{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c4bcd7-3c78-4eee-87f7-e43f8decd338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from derive_conceptualspace.evaluate.shallow_trees import classify_shallowtree\n",
    "from derive_conceptualspace.pipeline import SnakeContext, load_envfiles\n",
    "from derive_conceptualspace.util.result_analysis_tools import get_best_conf, highlight_nonzero_max, highlight_max\n",
    "from derive_conceptualspace.cli.args_from_filename import get_filename, print_envvars\n",
    "from misc_util.logutils import setup_logging\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3699c87-e4b5-4a90-a054-81266da1d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "import pyperclip\n",
    "from derive_conceptualspace.util.result_analysis_tools import df_to_latex\n",
    "from misc_util.logutils import setup_logging\n",
    "from misc_util.pretty_print import display, pretty_print as print\n",
    "from derive_conceptualspace.util.threedfigure import ThreeDFigure\n",
    "from derive_conceptualspace.semantic_directions.cluster_names import get_name_dict\n",
    "from derive_conceptualspace.pipeline import SnakeContext, load_envfiles, cluster_loader\n",
    "from derive_conceptualspace.util.result_analysis_tools import getfiles_allconfigs\n",
    "from derive_conceptualspace.util.desc_object import DescriptionList\n",
    "from derive_conceptualspace.evaluate.shallow_trees import classify_shallowtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e804b2-60e4-4915-89e8-9d06276d6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyperclip\n",
    "from derive_conceptualspace.util.result_analysis_tools import getfiles_allconfigs\n",
    "from derive_conceptualspace.util.result_analysis_tools import df_to_latex, shorten_met\n",
    "from derive_conceptualspace.util.desc_object import DescriptionList\n",
    "from derive_conceptualspace.pipeline import cluster_loader\n",
    "from joblib import parallel_backend\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from IPython.display import Markdown\n",
    "flatten = lambda l: [item for sublist in l for item in sublist] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a280efe-7d9e-4c79-b16d-d33add8ba04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging()\n",
    "load_envfiles(\"siddata\")\n",
    "configs, print_cnf = getfiles_allconfigs(\"clusters\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c16b4-24e9-4a4e-8424-ba5d1d03b336",
   "metadata": {},
   "source": [
    "# All configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95471de0-f89e-4fe5-bfca-950c6f0d30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decisions(X_test, clf, catnames, axnames):\n",
    "    n_nodes = clf.tree_.node_count\n",
    "    children_left = clf.tree_.children_left\n",
    "    children_right = clf.tree_.children_right\n",
    "    classes = [catnames[clf.classes_[np.argmax(i)]] for i in clf.tree_.value]\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "    while len(stack) > 0:\n",
    "        # `pop` ensures each node is only visited once\n",
    "        node_id, depth = stack.pop()\n",
    "        node_depth[node_id] = depth\n",
    "        # If the left and right child of a node is not the same we have a split node\n",
    "        is_split_node = children_left[node_id] != children_right[node_id]\n",
    "        # If a split node, append left and right children and depth to `stack` so we can loop through them\n",
    "        if is_split_node:\n",
    "            stack.append((children_left[node_id], depth + 1))\n",
    "            stack.append((children_right[node_id], depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "    alls = {}\n",
    "    for i in range(n_nodes):\n",
    "        if not is_leaves[i]:\n",
    "            alls.setdefault(node_depth[i], []).append((axnames[clf.tree_.feature[i]], clf.tree_.threshold[i]))  \n",
    "    return (alls[0]+alls[1]) if len(alls) > 1 else alls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8230dff4-bcdf-4b35-9430-43b5feaa16f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alls = None\n",
    "nworked = 0\n",
    "for conf in configs: #[i for i in configs if i[\"embed_dimensions\"] == NDIM][16:]: #first 10 have <10\n",
    "    ctx = SnakeContext.loader_context(config={**conf, \"debug\": False}, silent=True)\n",
    "    clusters = ctx.load(\"clusters\", loaders=dict(clusters=cluster_loader))\n",
    "    if len(clusters[\"clusters\"]) < conf[\"embed_dimensions\"]*2:\n",
    "        print(f'Skipping... ({len(clusters[\"clusters\"])} clusters)')\n",
    "        continue\n",
    "    nworked += 1\n",
    "    descriptions, embedding = ctx.load(\"pp_descriptions\", \"embedding\", \n",
    "                  loaders=dict(pp_descriptions=DescriptionList.from_json, clusters=cluster_loader, embedding=lambda **args: args[\"embedding\"].embedding_))\n",
    "    clfs, inputs, targets, scores, classes, catnames = classify_shallowtree(clusters, embedding, descriptions, ctx.obj[\"dataset_class\"], one_vs_rest=True, dt_depth=1, test_percentage_crossval=0.33,\n",
    "                       classes=\"fachbereich\", verbose=False, return_features=True, balance_classes=True, do_plot=False, shutup=True)\n",
    "    if alls is None:\n",
    "        alls = {i[1]: {int(j): [] for j in print_cnf[\"embed_dimensions\"]}  for i in classes}\n",
    "    \n",
    "    axnames = {n: k for n, k in enumerate(clusters[\"clusters\"].keys())}\n",
    "    for clf, catname in zip(clfs, classes):\n",
    "        feats = [(i[0], round(i[1],3)) for i in sorted({axnames[i]: elem for i, elem in enumerate(clf.feature_importances_) if elem > 0}.items(), key=lambda x:x[1], reverse=True)][:3]\n",
    "        alls[catname[1]][conf[\"embed_dimensions\"]].append([i[0] for i in feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe540bc3-eca7-4cad-9ab7-268e649bec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de7c1e-d1a7-48f3-bf9f-9d739f602a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_goodruns = {k: len(v) for k, v in list(alls.values())[0].items()}\n",
    "print(f\"How many per dim have at least ndims*2 features with kappa > 0.5: {num_goodruns}\")\n",
    "\n",
    "flattened = {k1: {k2: set([i[0] for i in v2]) for k2, v2 in v1.items()} for k1, v1 in alls.items()}\n",
    "nums = {k1: {k2: len(v2) for k2, v2 in v1.items()} for k1, v1 in flattened.items()}\n",
    "print(f\"How many unique per dim are there:\")\n",
    "nums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01260c5d-fc85-4106-881a-a9156a109522",
   "metadata": {},
   "source": [
    "Ok let us ignore 3-dim cause that obvs sucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda7c5d8-ff58-44ce-8209-1d8f244c5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = {k1: {k2: v2 for k2, v2 in v1.items() if k2 != 3} for k1, v1 in flattened.items()}\n",
    "\n",
    "fullflat = {k1: flatten([v2 for v2 in v1.values()]) for k1, v1 in flattened.items()}\n",
    "nums = {k1: len(set(v1)) for k1, v1 in fullflat.items()}\n",
    "print(f\"How many unique in sum are there (out of {sum(i[1] for i in num_goodruns.items() if i[0] != 3)} possible)\")\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798002b1-3da0-49c2-9d2a-9376a2a61eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: {f\"{k2} ({v2})\" for k2, v2 in dict(Counter(v)).items() if v2 > 1} for k, v in fullflat.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4280e1-434f-4101-b8c2-19ec69bb54c9",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Are intuitively appealing phrases among the semantic directions?\n",
    "\n",
    "Given the task of manually embedding courses into a semantic space, there are some intuitive can-\n",
    "didates one may think of that capture some important aspects of a course. For\n",
    "example, a word like computer hinting at computer-science related courses. Other\n",
    "obvious candidates that will be checked include math, culture, science, school and\n",
    "sport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb920245-b1de-42ea-b257-b8737d0a5b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fullflat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e70756f-6b69-4acf-9902-a8e5ef808160",
   "metadata": {},
   "outputs": [],
   "source": [
    "builtins.print('\\n'.join(k.ljust(max(len(i)+1 for i in fullflat.keys()))+'   '+(', '.join(v)) for k, v in fullflat.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee410cd-5d61-4ca6-8088-a564e172f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "consider = [\"computer\", \"recht\", \"musik\", \"management\", \"literatur\", \"sprache\", \"psychologie\", \"wirtschaft\", \"geographie\", \"schule\", \"kultur\", \"wissenschaft\", \"sport\"]\n",
    "\n",
    "print(\"Checking if it is a T^0.5 term\")\n",
    "for i in consider:\n",
    "    if [k for k, v in fullflat.items() if i in v]:\n",
    "        print(i, [k for k, v in fullflat.items() if i in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2910a5-65c5-4ffd-8db9-cde49684434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst_to_di(lst):\n",
    "    dict_of_elems = {}\n",
    "    for key, val in lst:\n",
    "        dict_of_elems.setdefault(key, []).append(val)\n",
    "    return dict_of_elems\n",
    "\n",
    "full = {}\n",
    "for i in consider:\n",
    "    lst = [(k, v2) for k, v in fullflat.items() for v2 in v if i in v2]\n",
    "    if lst: full.update(**lst_to_di(lst))\n",
    "\n",
    "print(\"Checking if it is part of a T^0.5 term\")\n",
    "builtins.print('\\n'.join(k.ljust(max(len(i)+1 for i in full.keys()))+'   '+(', '.join(v)) for k, v in full.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330cc648-e438-49a5-831f-1ed024e14697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adf8cf50-b822-4c0e-9126-febc77574d9b",
   "metadata": {},
   "source": [
    "# Ok, now for ALL ones\n",
    "\n",
    "(also robustness assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c20ed-1d82-4c92-8434-647a9c9efe60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_centers, all_elems = {int(j): [] for j in print_cnf[\"embed_dimensions\"]}, {int(j): [] for j in print_cnf[\"embed_dimensions\"]}\n",
    "nworked = 0\n",
    "for conf in configs: #[i for i in configs if i[\"embed_dimensions\"] == NDIM][16:]: #first 10 have <10\n",
    "    ctx = SnakeContext.loader_context(config={**conf, \"debug\": False}, silent=True)\n",
    "    clusters = ctx.load(\"clusters\", loaders=dict(clusters=cluster_loader))\n",
    "    if len(clusters[\"clusters\"]) < conf[\"embed_dimensions\"]*2:\n",
    "        print(f'Skipping... ({len(clusters[\"clusters\"])} clusters)')\n",
    "        continue\n",
    "    all_centers[conf[\"embed_dimensions\"]].append(set(clusters[\"clusters\"].keys()))\n",
    "    all_elems[conf[\"embed_dimensions\"]].append(set(flatten(clusters[\"clusters\"].values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181f07e-77b0-4cdf-90b5-537770ba7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_centers = {k2: v2 for k2, v2 in all_centers.items() if k2 != 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f681d0-c322-46c6-890d-878bb86d1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_centers[50]), len(flatten(all_centers[50])), len(set(flatten(all_centers[50]))))\n",
    "print(len(all_centers[200]), len(flatten(all_centers[200])), len(set(flatten(all_centers[200]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e27d6-4a68-4f73-8668-b42f9160c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from derive_conceptualspace.util.result_analysis_tools import df_to_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e905ae77-cecf-4767-8ddd-4d5eec92a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(index=consider, columns=pd.MultiIndex.from_tuples([(i,j) for i in all_centers.keys() for j in (\"0.1\", \"0.5\")], names=(\"NDim\", \"T\")))\n",
    "for what, whatname in [(all_centers, \"0.5\"), (all_elems, \"0.1\")]:\n",
    "    for ndim in all_centers.keys():\n",
    "        df.loc[\"N\", (ndim, whatname)] = len(what[ndim])\n",
    "        for i in consider:\n",
    "            df.loc[i, (ndim, whatname)] = sum(1 for j in what[ndim] if i in j)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2a33ef-e14c-45a5-a5a9-973de1d41509",
   "metadata": {},
   "outputs": [],
   "source": [
    "builtins.print(df_to_latex(df, lambda x:x.style))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7ba89-7366-4dfe-8654-55c383b1e430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
